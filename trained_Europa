# -*- coding: utf-8 -*-
"""trained_Europa.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1avhZCYZnX45qGCld5fi2oWc8fqbwNy1g
"""

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from google.colab import drive
import datetime as dt
import sklearn
drive.mount('/content/drive')

data = '/content/drive/MyDrive/TFM - Palladium/PROYECTO LIMPIO/Archivos CSV/europa_sin_covid.csv'
df_data = pd.read_csv(data, sep=",")
df_data

#Cambiamos formato de fecha
df_data['FECHA_TTOO'] = pd.to_datetime(df_data['FECHA_TTOO'], format="%Y-%m-%d %H:%M:%S")

#Cambiamos formato de fecha LLEGADA
df_data['LLEGADA'] = pd.to_datetime(df_data['LLEGADA'], format="%Y-%m-%d")

#Creamos columna con los d√≠as de pre. de reserva hasta la llegada
df_data["LEAD_TIME"] = (df_data['LLEGADA'] - df_data['FECHA_TTOO']).dt.days

df_data["MES_LLEGADA"] = df_data['LLEGADA'].dt.month

df_data["WEEK_LLEGADA"] = df_data['LLEGADA'].dt.week

df_data["WEEKDAY_LLEGADA"] = df_data['LLEGADA'].dt.weekday

from sklearn.model_selection import KFold

from sklearn.model_selection import StratifiedKFold

folds = StratifiedKFold(n_splits=5, random_state=0, shuffle=True)

df_data = pd.get_dummies(df_data, columns = ["FIDELIDAD",'TIPO_CLIENTE'])

from sklearn.model_selection import train_test_split
feature_list=["NOCHES","ADR","PAX", "LEAD_TIME", "FIDELIDAD_Palladium Rewards", "FIDELIDAD_Palladium Connect", "MES_LLEGADA", "WEEKDAY_LLEGADA", "WEEK_LLEGADA",'TIPO_CLIENTE_1', 'TIPO_CLIENTE_2', 'TIPO_CLIENTE_3', 'TIPO_CLIENTE_9']
#X = df_data.drop("ESTADO_RESERVA", axis = 1)
X = df_data[feature_list]
feature_names = X.columns
X = X.values

y = df_data["ESTADO_RESERVA"].values

X_train, X_test, y_train, y_test = train_test_split(
    X, y, random_state=0, test_size=0.2, stratify=y
)

df_data

df_data["TIPO_CLIENTE_1"].unique

np.unique(df_data["TIPO_CLIENTE_1"])

"""Bagging (Random Forest)"""

#Bagging (Random Forest)
#Con none pilla la maoyor profundidad posible, random classfier cuanto menos estimators mas complejo
from sklearn.ensemble import RandomForestClassifier
from sklearn.metrics import roc_auc_score

metrics = []

for n, (i_train_fold, i_val_fold) in enumerate(folds.split(X_train, y_train)):

  x = X_train[i_train_fold]
  y = y_train[i_train_fold]
  x_val = X_train[i_val_fold]
  y_val = y_train[i_val_fold]

  rf = RandomForestClassifier(n_estimators = 150, max_depth=	13).fit(x, y)
  y_pred = rf.predict_proba(x)[:, 1]
  y_pred_val = rf.predict_proba(x_val)[:, 1]

  auc_train = roc_auc_score(y, y_pred)
  auc_val = roc_auc_score(y_val, y_pred_val)
  
  metrics.append((auc_train, auc_val))

  print(f"Fold #{n + 1}: auc_train {auc_train: .4f} - auc_val {auc_val: .4f}")

import pickle

with open('rf.pkl', 'wb') as handle:
    pickle.dump(rf, handle, protocol=pickle.HIGHEST_PROTOCOL)

with open('rf.pkl', 'rb') as handle:
    rf = pickle.load(handle)

ls
